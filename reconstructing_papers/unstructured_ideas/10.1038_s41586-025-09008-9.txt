Animal choice behaviour involves both reward-seeking actions and repetition of past actions, which theory suggests are reinforced by distinct dopaminergic teaching signals. Reward prediction error signals reinforce value-based associations while movement-based action prediction errors reinforce value-free repetitive associations through separate neural pathways. Movement-related dopamine activity in the tail of the striatum potentially encodes action prediction error signals that operate independently of reward value. An auditory discrimination task in mice can reveal whether striatal dopamine encodes action prediction errors by measuring movement-related neural activity during sound-action learning. Causal manipulations of this dopamine activity can test whether action prediction errors function as value-free teaching signals that reinforce repeated associations. Computational modelling paired with behavioral experiments can demonstrate how action prediction errors work alongside reward prediction error circuitry to consolidate stable sound-action associations without value dependence. This approach tests whether two types of dopaminergic prediction errors operate in tandem across different striatal areas to support distinct forms of associative learning.